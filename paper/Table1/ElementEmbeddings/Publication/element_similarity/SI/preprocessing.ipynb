{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "This notebook is here to show how the embedding files are processed prior to any calculations and explain any design decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from elementembeddings.core import Embedding, data_directory\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block loads all the embedding files currently packaged within the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the representations packaged\n",
    "rep_folder = os.listdir(f\"{data_directory}/element_representations\")\n",
    "\n",
    "# Filter out any files which are not json or csv files\n",
    "rep_files = [rep for rep in rep_folder if rep.endswith(\".csv\") or rep.endswith(\".json\")]\n",
    "\n",
    "# Print the filenames\n",
    "print(rep_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings\n",
    "\n",
    "embedding_dict = {}\n",
    "\n",
    "# Use functions of the Embedding class to load these raw data.\n",
    "for rep in rep_files:\n",
    "    if rep.endswith(\".csv\"):\n",
    "        name = rep.split(\".\")[0]\n",
    "        embedding_dict[name] = {\n",
    "            \"embedding\": Embedding.from_csv(\n",
    "                f\"{data_directory}/element_representations/{rep}\", name\n",
    "            )\n",
    "        }\n",
    "    elif rep.endswith(\".json\"):\n",
    "        name = rep.split(\".json\")[0]\n",
    "        embedding_dict[name] = {\n",
    "            \"embedding\": Embedding.from_json(\n",
    "                f\"{data_directory}/element_representations/{rep}\", name\n",
    "            )\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check to see if any of the embedding files have missing values. To do this, we will load each embedding as a dataframe and verify if any of the columns of the dataframe (i.e. the individual vector components) have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "\n",
    "for embedding in embedding_dict.values():\n",
    "    df = embedding[\"embedding\"].as_dataframe()\n",
    "    embedding[\"dataframe\"] = df\n",
    "    print(\n",
    "        f\"For {embedding['embedding'].embedding_name} there are {df.isna().any().sum()} features with missing values\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict[\"oliynyk\"][\"dataframe\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a bool series for columns to check for missing values\n",
    "olinyk_columns_bool = embedding_dict[\"oliynyk\"][\"dataframe\"].isna().any()\n",
    "\n",
    "# Print the columns with missing values\n",
    "missing_val_cols = olinyk_columns_bool[olinyk_columns_bool == True]\n",
    "print(missing_val_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of the missing-value columns:\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "for ax, col in zip(axes.flatten(), list(missing_val_cols.index)):\n",
    "    sns.histplot(data=embedding_dict[\"oliynyk\"][\"dataframe\"], x=col, ax=ax)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "We will try different strategies to impute the missing values while trying to keep the distributions the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Imputing\n",
    "oliynyk_dfs = {\"original\": embedding_dict[\"oliynyk\"][\"dataframe\"].copy()}\n",
    "\n",
    "# The constant value is zero by default\n",
    "strategies = [\"mean\", \"median\", \"most_frequent\", \"constant\"]\n",
    "\n",
    "for strat in strategies:\n",
    "    imp = SimpleImputer(strategy=strat)\n",
    "    df = oliynyk_dfs[\"original\"].copy()\n",
    "    index, columns = df.index, df.columns\n",
    "    X = df.values\n",
    "    X_imp = imp.fit_transform(X)\n",
    "\n",
    "    df_imp = pd.DataFrame(data=X_imp, index=index, columns=columns)\n",
    "    oliynyk_dfs[f\"{strat}\"] = df_imp\n",
    "\n",
    "    # Verify if there are missing values\n",
    "    print(\n",
    "        f\"The original dataframe had {df.isna().any().sum()} missing values. Using {strat}-imputing, the new dataframe now has {df_imp.isna().any().sum()} missing values\"\n",
    "    )\n",
    "\n",
    "\n",
    "# knn imputing\n",
    "knn_imp = KNNImputer()\n",
    "df = oliynyk_dfs[\"original\"].copy()\n",
    "index, columns = df.index, df.columns\n",
    "X = df.values\n",
    "X_imp = knn_imp.fit_transform(X)\n",
    "df_imp = pd.DataFrame(data=X_imp, index=index, columns=columns)\n",
    "oliynyk_dfs[\"knn\"] = df_imp\n",
    "print(\n",
    "    f\"Using knn-imputing, the new dataframe now has {df_imp.isna().any().sum()} missing values.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of the missing-value columns:\n",
    "\n",
    "for col in list(missing_val_cols.index):\n",
    "    fig, axes = plt.subplots(3, 2)\n",
    "    for ax, imp in zip(axes.flatten(), oliynyk_dfs.keys()):\n",
    "        sns.histplot(data=oliynyk_dfs[imp], x=col, ax=ax)\n",
    "        if imp == \"original\":\n",
    "            ax.set_title(\"Original\")\n",
    "        else:\n",
    "            ax.set_title(f\"{imp} imputing\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict[\"oliynyk_sc\"][\"dataframe\"].columns = embedding_dict[\"oliynyk\"][\n",
    "    \"dataframe\"\n",
    "].columns\n",
    "embedding_dict[\"oliynyk\"][\"dataframe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graphs, we can see for `Mulliken_EN`, `MB_electronegativity`, `crystal_radius`, knn imputation leaves the overall distribution unchanged. Whereas for the `Miracle_Radius_[pm]`, mode imputing keeps the overall distribution unchanged.\n",
    "\n",
    "For this particular work, we will create a new embedding file from the Oliynyk file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode impute the miracle radius\n",
    "oliynyk_df = oliynyk_dfs[\"original\"].copy()\n",
    "imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "X = oliynyk_df[\"Miracle_Radius_[pm]\"].values.reshape(-1, 1)\n",
    "X_imp = imp.fit_transform(X)\n",
    "\n",
    "oliynyk_df[\"Miracle_Radius_[pm]\"] = X_imp\n",
    "\n",
    "# knn impute the other 3 variables\n",
    "knn_imp = KNNImputer()\n",
    "index, columns = oliynyk_df.index, oliynyk_df.columns\n",
    "X = df.values\n",
    "X_imp = knn_imp.fit_transform(X)\n",
    "oliynyk_df = pd.DataFrame(data=X_imp, index=index, columns=columns)\n",
    "print(\n",
    "    f\"The new dataframe has {oliynyk_df.isna().any().sum()} columns with missing values\"\n",
    ")\n",
    "oliynyk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the new dataframe.\n",
    "\n",
    "oliynyk_df.to_csv(\n",
    "    f\"{data_directory}/element_representations/oliynyk_preprocessed.csv\",\n",
    "    index=True,\n",
    "    index_label=\"element\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomic_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
