{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating pairwise cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from elementembeddings.core import Embedding, data_directory\n",
    "from smact.structure_prediction.utilities import parse_spec\n",
    "import smact\n",
    "from smact.data_loader import (\n",
    "    lookup_element_oxidation_states_icsd,\n",
    "    lookup_element_oxidation_states,\n",
    "    lookup_element_oxidation_states_sp,\n",
    ")\n",
    "from smact.structure_prediction.utilities import unparse_spec\n",
    "import os\n",
    "\n",
    "# Load the embeddings\n",
    "cbfvs = [\n",
    "    \"magpie\",\n",
    "    \"matscholar\",\n",
    "    \"mat2vec\",\n",
    "    \"megnet16\",\n",
    "    \"oliynyk\",\n",
    "    \"random_200\",\n",
    "    \"skipatom\",\n",
    "]\n",
    "element_embeddings = {cbfv: Embedding.load_data(cbfv) for cbfv in cbfvs}\n",
    "\n",
    "# Standardise\n",
    "for embedding in element_embeddings.values():\n",
    "    print(f\"Attempting to standardise {embedding.embedding_name}...\")\n",
    "    print(f\" Already standardised: {embedding.is_standardised}\")\n",
    "    embedding.standardise(inplace=True)\n",
    "    print(f\"Now standardised: {embedding.is_standardised}\")\n",
    "# Keep the first 83 elements\n",
    "\n",
    "# Get the ordered symbols file\n",
    "symbols_path = os.path.join(data_directory, \"element_data\", \"ordered_periodic.txt\")\n",
    "with open(symbols_path) as f:\n",
    "    symbols = f.read().splitlines()\n",
    "\n",
    "# Get the first 83 elements\n",
    "symbols = symbols[:83]\n",
    "\n",
    "for cbfv in cbfvs:\n",
    "    # Get the keys of the atomic embeddings object\n",
    "    elements = set(element_embeddings[cbfv].element_list)\n",
    "    el_symbols_set = set(symbols)\n",
    "\n",
    "    # Get the element symbols we want to remove\n",
    "    els_to_remove = list(elements - el_symbols_set)\n",
    "\n",
    "    # Iteratively delete the elements with atomic number\n",
    "    # greater than 83 from our embeddings\n",
    "    for el in els_to_remove:\n",
    "        del element_embeddings[cbfv].embeddings[el]\n",
    "\n",
    "    # Verify that we have 83 elements\n",
    "    print(len(element_embeddings[cbfv].element_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating list of species\n",
    "\n",
    "The current version of the SMACT structure prediction is based on using species rather than elements. To circumvent that, we create table of pairwise lambda values for the species by assuming all species for a given element will take the same cosine similarity.\n",
    "\n",
    "We acknowledge that this is not an accurate assumption, but in this work, with a focus on unary substitutions where we are not trying to assign structures to hypothetical compositions as well as charge-neutrality being enforced in the substitutions, this should not lead to odd predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMACT is used to get a list of species\n",
    "species = []\n",
    "for element in symbols:\n",
    "    oxidation_states = lookup_element_oxidation_states(element)\n",
    "    for oxidation_state in oxidation_states:\n",
    "        species.append(unparse_spec((element, oxidation_state)))\n",
    "\n",
    "print(len(species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the pairwise cosine similarities.\n",
    "\n",
    "\n",
    "if not os.path.exists(\"cosine_similarity/\"):\n",
    "    os.mkdir(\"cosine_similarity/\")\n",
    "table_dict = {}\n",
    "species_pairs = list(itertools.combinations_with_replacement(species, 2))\n",
    "for cbfv in element_embeddings.keys():\n",
    "    print(cbfv)\n",
    "    table = []\n",
    "    for spec1, spec2 in species_pairs:\n",
    "        corr = element_embeddings[cbfv].compute_correlation_metric(\n",
    "            parse_spec(spec1)[0], parse_spec(spec2)[0], metric=\"pearson\"\n",
    "        )\n",
    "        table.append([spec1, spec2, corr])\n",
    "        if spec1 != spec2:\n",
    "            table.append([spec2, spec1, corr])\n",
    "    table_dict[cbfv] = table\n",
    "    with open(f\"cosine_similarity/{cbfv}.json\", \"w\") as f:\n",
    "        json.dump(table, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
