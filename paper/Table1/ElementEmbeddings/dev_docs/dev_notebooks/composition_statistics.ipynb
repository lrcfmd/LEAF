{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compositional statistics development\n",
    "\n",
    "This notebook is for prototyping the implementation of compositional statistics for the Compositon class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AtomicEmbeddings.core import Embedding\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from AtomicEmbeddings.composition import CompositionalEmbedding\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "\n",
    "CsPbI3_magpie = CompositionalEmbedding(formula=\"CsPbI3\", embedding=\"magpie\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics we want to implement are:\n",
    "\n",
    "* Weighted mean: $\\bar{x} = \\sum_{i=1}^n w_i x_i$\n",
    "* Weighted sum: $\\sum_{i=1}^n w_i x_i$\n",
    "* Weighted variance: $s^2 = \\sum_{i=1}^n w_i (x_i - \\bar{x})^2$\n",
    "* Min-pooling: $\\min_{i=1}^n x_i$\n",
    "* Max-pooling: $\\max_{i=1}^n x_i$\n",
    "\n",
    "If we consider a ternary compound, $A_aB_bC_c$, we can represent the individual elements with a features of dimension of N, indicated by $f_{A,i}$, $f_{B,i}$ and $f_{C,i}$($i=1,...N$).\n",
    "\n",
    "The statistics can be represented as:\n",
    "\n",
    "* Weighted mean: $f_{mean,i} = a^{*} f_{A,i} + b^{*} f_{B,i} + c^{*} f_{C,i}$\n",
    "* Weighted sum: $f_{sum,i} = a f_{A,i} + b f_{B,i} + c f_{C,i}$\n",
    "* Weighted variance: $f_{var,i} = a^{*} (f_{A,i} - f_{mean,i})^2 + b^{*} (f_{B,i} - f_{mean,i})^2 + c^{*} (f_{C,i} - f_{mean,i})^2$\n",
    "* Min-pooling: $f_{min,i} = \\min(f_{A,i}, f_{B,i}, f_{C,i})$\n",
    "* Max-pooling: $f_{max,i} = \\max(f_{A,i}, f_{B,i}, f_{C,i})$\n",
    "\n",
    "where $a^{*} = \\frac{a}{a+b+c}$, $b^{*} = \\frac{b}{a+b+c}$ and $c^{*} = \\frac{c}{a+b+c}$, denoting the normalized stoichiometry of the compound."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A matrix representation of the element features\n",
    "\n",
    "We can represent the element features as a matrix, $F$, of dimension $3 \\times N$, where $N$ is the number of features and 3 is the number of elements. The matrix is defined as:\n",
    "\n",
    "$F = \\begin{bmatrix} f_{A,1} & f_{A,2} & \\cdots & f_{A,N} \\\\ f_{B,1} & f_{B,2} & \\cdots & f_{B,N} \\\\ f_{C,1} & f_{C,2} & \\cdots & f_{C,N} \\end{bmatrix}$\n",
    "\n",
    "## A matrix representation of the stoichiometry\n",
    "\n",
    "We can represent the stoichiometry as a matrix, $S$, of dimension $1 \\times 3$, where 3 is the number of elements. The matrix is defined as:\n",
    "\n",
    "$S = \\begin{bmatrix} a & b & c \\end{bmatrix}$\n",
    "\n",
    "We can represent the normalized stoichiometry as a matrix, $S^{*}$, of dimension $1 \\times 3$, where 3 is the number of elements. The matrix is defined as:\n",
    "\n",
    "$S^{*} = \\begin{bmatrix} a^{*} & b^{*} & c^{*} \\end{bmatrix}$\n",
    "\n",
    "## Implementing the statistics\n",
    "\n",
    "We can implement the statistics using `numpy`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A matrix representation of the the weighted mean\n",
    "\n",
    "We can represent the weighted mean as a matrix, $F_{mean}$, of dimension $1 \\times N$, where $N$ is the number of features. The matrix is defined as:\n",
    "\n",
    "$F_{mean} = \\begin{bmatrix} f_{mean,1} & f_{mean,2} & \\cdots & f_{mean,N} \\end{bmatrix}$\n",
    "\n",
    "This matrix can be calculated as:\n",
    "\n",
    "$F_{mean} = S^{*} \\cdot F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the matrix of element embeddings\n",
    "\n",
    "n = int(len(CsPbI3_magpie.fractional_composition))\n",
    "m = len(CsPbI3_magpie.embedding.embeddings[\"H\"])\n",
    "el_matrix = np.zeros(shape=(n, m))\n",
    "for i, k in enumerate(CsPbI3_magpie.fractional_composition.keys()):\n",
    "    el_matrix[i] = CsPbI3_magpie.embedding.embeddings[k]\n",
    "\n",
    "print(f\" We have {n} elements in the formula and {m} features per element.\")\n",
    "print(f\" The shape of the element matrix is {el_matrix.shape}\")\n",
    "print(el_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate the weighted mean feature vector by taking the dot product of the fractional composition and the element matrix\n",
    "\n",
    "# Get the stoichiometric vector\n",
    "stoich_vector = np.array(list(CsPbI3_magpie.fractional_composition.values()))\n",
    "print(f\" The stoichiometric vector is {stoich_vector}\")\n",
    "mean_vector = np.dot(stoich_vector, el_matrix)\n",
    "print(f\" The mean vector is \\n {mean_vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use numpy.average to calculate the weighted mean\n",
    "mean_vector_2 = np.average(el_matrix, axis=0, weights=stoich_vector)\n",
    "print(f\" The mean vector is \\n {mean_vector_2}\")\n",
    "\n",
    "print(mean_vector == mean_vector_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the two methods\n",
    "%timeit np.dot(stoich_vector, el_matrix)\n",
    "%timeit np.average(el_matrix, axis=0, weights=stoich_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using np.dot() is quicker than using np.average() to calculate the mean feature vector. As such, we will use np.dot() to calculate the weighted mean."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A matrix representation of the the weighted sum\n",
    "\n",
    "We can represent the weighted sum as a matrix, $F_{sum}$, of dimension $1 \\times N$, where $N$ is the number of features. The matrix is defined as:\n",
    "\n",
    "$F_{sum} = \\begin{bmatrix} f_{sum,1} & f_{sum,2} & \\cdots & f_{sum,N} \\end{bmatrix}$\n",
    "\n",
    "This matrix can be calculated as:\n",
    "\n",
    "$F_{sum} = S \\cdot F$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate the weighted sum feature vector by taking the dot product of the stoichiometric vector and the element matrix\n",
    "\n",
    "stoich_vector_unweighted = np.array(list(CsPbI3_magpie.composition.values()))\n",
    "print(f\" The stoichiometric vector is {stoich_vector_unweighted}\")\n",
    "\n",
    "sum_vector = np.dot(stoich_vector_unweighted, el_matrix)\n",
    "print(f\" The sum vector is \\n {sum_vector}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A matrix representation of the the weighted variance\n",
    "\n",
    "We can represent the weighted variance as a matrix, $F_{var}$, of dimension $1 \\times N$, where $N$ is the number of features. The matrix is defined as:\n",
    "\n",
    "$F_{var} = \\begin{bmatrix} f_{var,1} & f_{var,2} & \\cdots & f_{var,N} \\end{bmatrix}$\n",
    "\n",
    "This matrix can be calculated as:\n",
    "\n",
    "$F_{var} = S^{*} \\cdot (F - F_{mean})^2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate the weighted variance feature vector by\n",
    "# 1. Subtracting the mean vector from each element embedding\n",
    "# 2. Squaring the result\n",
    "# 3. Taking the dot product of the squared difference and the stoichiometric vector\n",
    "\n",
    "# 1. Subtract the mean vector from each element embedding\n",
    "el_matrix_mean_subtracted = el_matrix - mean_vector\n",
    "\n",
    "# 2. Square the result\n",
    "el_matrix_mean_subtracted_squared = el_matrix_mean_subtracted**2\n",
    "\n",
    "# 3. Take the dot product of the squared difference and the stoichiometric vector\n",
    "var_vector = np.dot(stoich_vector, el_matrix_mean_subtracted_squared)\n",
    "print(f\" The variance vector is \\n {var_vector}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A matrix representation of the the min-pooling\n",
    "\n",
    "We can represent the min-pooling as a matrix, $F_{min}$, of dimension $1 \\times N$, where $N$ is the number of features. The matrix is defined as:\n",
    "\n",
    "$F_{min} = \\begin{bmatrix} f_{min,1} & f_{min,2} & \\cdots & f_{min,N} \\end{bmatrix}$\n",
    "\n",
    "This matrix can be calculated as:\n",
    "\n",
    "$F_{min} = \\min(F)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate the weighted minpool feature vector by taking the minimum of each column of the element matrix\n",
    "\n",
    "min_vector = np.min(el_matrix, axis=0)\n",
    "print(f\" The min vector is \\n {min_vector}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A matrix representation of the the max-pooling\n",
    "\n",
    "We can represent the max-pooling as a matrix, $F_{max}$, of dimension $1 \\times N$, where $N$ is the number of features. The matrix is defined as:\n",
    "\n",
    "$F_{max} = \\begin{bmatrix} f_{max,1} & f_{max,2} & \\cdots & f_{max,N} \\end{bmatrix}$\n",
    "\n",
    "This matrix can be calculated as:\n",
    "\n",
    "$F_{max} = \\max(F)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate the weighted maxpool feature vector by taking the maximum of each column of the element matrix\n",
    "\n",
    "max_vector = np.max(el_matrix, axis=0)\n",
    "print(f\" The max vector is \\n {max_vector}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other statistics\n",
    "\n",
    "We can also implement other statistics, such as the median, mode, standard deviation, etc. However, these statistics are not as useful as the ones listed above. As such, we will not implement them.\n",
    "\n",
    "These other statistics be represented as:\n",
    "\n",
    "* Geometry mean: $\\sqrt[N]{\\prod_{i=1}^n x_i}$\n",
    "* Harmonic mean: $\\frac{n}{\\sum_{i=1}^n \\frac{1}{x_i}}$\n",
    "\n",
    "For our ternary compounds, we can represent the geometry mean as:\n",
    "\n",
    "* Geometry mean: $f_{gmean,i}=\\sqrt[a+b+c]{f_{A,i}^{a} \\cdot f_{B,i}^{b} \\cdot f_{C,i}^{c}}$\n",
    "* Harmonic mean: $f_{hmean,i}=\\frac{a+b+c}{\\frac{1}{f_{A,i}}*a + \\frac{1}{f_{B,i}}*b + \\frac{1}{f_{C,i}}*c}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can calculate the range feature vector by taking the difference between the max and min vectors\n",
    "\n",
    "range_vector = np.max(el_matrix, axis=0) - np.min(el_matrix, axis=0)\n",
    "\n",
    "range_vector2 = np.ptp(el_matrix, axis=0)\n",
    "\n",
    "print(f\" The range vector is \\n {range_vector}\")\n",
    "print(f\" The range vector is \\n {range_vector2}\")\n",
    "\n",
    "# Time the two methods\n",
    "%timeit np.max(el_matrix, axis=0) - np.min(el_matrix, axis=0)\n",
    "%timeit np.ptp(el_matrix, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `np.ptp()` is quicker than calculating the max and min separately. As such, we will use `np.ptp()` to calculate the range."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the CompositionalEmbedding object\n",
    "The feature vectors have now been integrated into the CompositionalEmbedding object.\n",
    "\n",
    "Let's test the calculation of feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_vector(comp_embed, stats=[\"mean\"]):\n",
    "    \"\"\"\n",
    "    Computes a feature vector based on the statistics specified in the stats argument\n",
    "\n",
    "    Args:\n",
    "        stats (list): A list of strings specifying the statistics to be computed. The default is ['mean'].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A feature vector of the s times the dimension of the embedding vector where s is the number of statistics specified in the stats argument\n",
    "    \"\"\"\n",
    "    if isinstance(stats, str):\n",
    "        stats = [stats]\n",
    "    if not isinstance(stats, list):\n",
    "        raise ValueError(\"Stats argument must be a list of strings\")\n",
    "    if not all([isinstance(s, str) for s in stats]):\n",
    "        raise ValueError(\"Stats argument must be a list of strings\")\n",
    "    if not all(\n",
    "        [\n",
    "            s\n",
    "            in [\n",
    "                \"mean\",\n",
    "                \"variance\",\n",
    "                \"minpool\",\n",
    "                \"maxpool\",\n",
    "                \"range\",\n",
    "                \"sum\",\n",
    "                \"geometric_mean\",\n",
    "                \"harmonic_mean\",\n",
    "            ]\n",
    "            for s in stats\n",
    "        ]\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\" {[stat for stat in stats if stat not in ['mean','variance','minpool','maxpool','range','sum','geometric_mean','harmonic_mean']]} are not valid statistics.\"\n",
    "        )\n",
    "    feature_vector = []\n",
    "    for s in stats:\n",
    "        if s == \"mean\":\n",
    "            feature_vector.append(comp_embed._mean_feature_vector())\n",
    "        elif s == \"variance\":\n",
    "            feature_vector.append(comp_embed._variance_feature_vector())\n",
    "        elif s == \"minpool\":\n",
    "            feature_vector.append(comp_embed._minpool_feature_vector())\n",
    "        elif s == \"maxpool\":\n",
    "            feature_vector.append(comp_embed._maxpool_feature_vector())\n",
    "        elif s == \"range\":\n",
    "            feature_vector.append(comp_embed._range_feature_vector())\n",
    "        elif s == \"sum\":\n",
    "            feature_vector.append(comp_embed._sum_feature_vector())\n",
    "        elif s == \"geometric_mean\":\n",
    "            feature_vector.append(comp_embed._geometric_mean_feature_vector())\n",
    "        elif s == \"harmonic_mean\":\n",
    "            feature_vector.append(comp_embed._harmonic_mean_feature_vector())\n",
    "    return np.concatenate(feature_vector)\n",
    "\n",
    "\n",
    "stats_functions_dict = {\n",
    "    \"mean\": \"_mean_feature_vector\",\n",
    "    \"variance\": \"_variance_feature_vector\",\n",
    "    \"minpool\": \"_minpool_feature_vector\",\n",
    "    \"maxpool\": \"_maxpool_feature_vector\",\n",
    "    \"range\": \"_range_feature_vector\",\n",
    "    \"sum\": \"_sum_feature_vector\",\n",
    "    \"geometric_mean\": \"_geometric_mean_feature_vector\",\n",
    "    \"harmonic_mean\": \"_harmonic_mean_feature_vector\",\n",
    "}\n",
    "\n",
    "\n",
    "def feature_vector_2(comp_embed, stats=[\"mean\"]):\n",
    "    \"\"\"\n",
    "    Computes a feature vector based on the statistics specified in the stats argument\n",
    "\n",
    "    Args:\n",
    "        stats (list): A list of strings specifying the statistics to be computed. The default is ['mean'].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A feature vector of the s times the dimension of the embedding vector where s is the number of statistics specified in the stats argument\n",
    "    \"\"\"\n",
    "    if isinstance(stats, str):\n",
    "        stats = [stats]\n",
    "    if not isinstance(stats, list):\n",
    "        raise ValueError(\"Stats argument must be a list of strings\")\n",
    "    if not all([isinstance(s, str) for s in stats]):\n",
    "        raise ValueError(\"Stats argument must be a list of strings\")\n",
    "    if not all(\n",
    "        [\n",
    "            s\n",
    "            in [\n",
    "                \"mean\",\n",
    "                \"variance\",\n",
    "                \"minpool\",\n",
    "                \"maxpool\",\n",
    "                \"range\",\n",
    "                \"sum\",\n",
    "                \"geometric_mean\",\n",
    "                \"harmonic_mean\",\n",
    "            ]\n",
    "            for s in stats\n",
    "        ]\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\" {[stat for stat in stats if stat not in ['mean','variance','minpool','maxpool','range','sum','geometric_mean','harmonic_mean']]} are not valid statistics.\"\n",
    "        )\n",
    "    feature_vector = []\n",
    "\n",
    "    for s in stats:\n",
    "        feature_vector.append(getattr(comp_embed, stats_functions_dict[s])())\n",
    "    return np.concatenate(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 100000 -r 10 feature_vector(CsPbI3_magpie, stats=[\"mean\", \"variance\", \"minpool\", \"maxpool\", \"range\", \"sum\"])\n",
    "%timeit -n 100000 -r 10 feature_vector_2(CsPbI3_magpie, stats=[\"mean\", \"variance\", \"minpool\", \"maxpool\", \"range\", \"sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%memit feature_vector(CsPbI3_magpie, stats=[\"mean\", \"variance\", \"minpool\", \"maxpool\", \"range\", \"sum\"])\n",
    "%memit feature_vector_2(CsPbI3_magpie, stats=[\"mean\", \"variance\", \"minpool\", \"maxpool\", \"range\", \"sum\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both versions of the feature vectors are execute in similar amount of time and use similar amount of memory.\n",
    "I will implement, the second version of the feature vectors, due to its better readability compared to the long chain of if-elif statements in the first version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composition_featuriser(\n",
    "    data: Union[pd.DataFrame, pd.Series, CompositionalEmbedding, list],\n",
    "    embedding: Union[Embedding, str] = \"magpie\",\n",
    "    stats: Union[str, list] = [\"mean\"],\n",
    "    inplace: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes a feature vector for a composition based on the statistics specified in the stats argument\n",
    "\n",
    "    Args:\n",
    "        data (Union[pd.DataFrame, pd.Series, list, CompositionalEmbedding]): A pandas DataFrame or Series containing a column named 'formula', a list of formula, or a CompositionalEmbedding class\n",
    "        embedding (Union[Embedding, str], optional): A Embedding class or a string\n",
    "        stats (Union[str, list], optional): A list of strings specifying the statistics to be computed. The default is ['mean'].\n",
    "        inplace (bool, optional): Whether to perform the operation in place on the data. The default is False.\n",
    "\n",
    "    Returns:\n",
    "        Union[pd.DataFrame,list]: A pandas DataFrame containing the feature vector, unless a list of formula is passed in which case a list of feature vectors is returned\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        if not inplace:\n",
    "            data = data.copy()\n",
    "        if \"formula\" not in data.columns:\n",
    "            raise ValueError(\n",
    "                \"The data must contain a column named 'formula' to featurise.\"\n",
    "            )\n",
    "        data[\"composition\"] = data[\"formula\"].apply(\n",
    "            lambda x: CompositionalEmbedding(x, embedding)\n",
    "        )\n",
    "        data[\"feature_vector\"] = data[\"composition\"].apply(\n",
    "            lambda x: x.feature_vector(stats)\n",
    "        )\n",
    "        data.drop(\"composition\", axis=1, inplace=True)\n",
    "        return data\n",
    "    elif isinstance(data, pd.Series):\n",
    "        if not inplace:\n",
    "            data = data.copy()\n",
    "        data[\"composition\"] = data[\"formula\"].apply(\n",
    "            lambda x: CompositionalEmbedding(x, embedding)\n",
    "        )\n",
    "        data[\"feature_vector\"] = data[\"composition\"].apply(\n",
    "            lambda x: x.feature_vector(stats)\n",
    "        )\n",
    "        data.drop(\"composition\", axis=1, inplace=True)\n",
    "        return data\n",
    "    elif isinstance(data, list):\n",
    "        comps = [CompositionalEmbedding(x, embedding) for x in data]\n",
    "        return [x.feature_vector(stats) for x in comps]\n",
    "\n",
    "    elif isinstance(data, CompositionalEmbedding):\n",
    "        return data.feature_vector(stats)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"The data must be a pandas DataFrame, Series, list or CompositionalEmbedding class.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_list = [\"CsPbI3\", \"CsPbBr3\", \"CsPbCl3\", \"CsPbF3\"]\n",
    "formula_dict = {\n",
    "    \"formula\": [\"CsPbI3\", \"CsPbBr3\", \"CsPbCl3\", \"CsPbF3\"],\n",
    "    \"target\": [1.5, 1.6, 1.7, 1.8],\n",
    "}\n",
    "formula_df = pd.DataFrame(formula_dict)\n",
    "formula_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(formula_list, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = composition_featuriser(\n",
    "    formula_df, stats=[\"mean\", \"sum\", \"variance\", \"minpool\", \"maxpool\", \"range\"]\n",
    ")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list = composition_featuriser(\n",
    "    formula_list, stats=[\"mean\", \"sum\", \"variance\", \"minpool\", \"maxpool\", \"range\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit composition_featuriser(formula_df, stats=[\"mean\", \"sum\", \"variance\", \"minpool\", \"maxpool\", \"range\"])\n",
    "%timeit composition_featuriser(formula_list, stats=[\"mean\", \"sum\", \"variance\", \"minpool\", \"maxpool\", \"range\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atomic_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bfad0b81df5b41ffb53bafa7f32021d99c9371dc7adb75c64dea2802f8c7fa9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
