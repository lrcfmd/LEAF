{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the ElementEmbeddings package\n",
    "This notebook will serve as a tutorial for using the ElementEmbeddings package and going over the core features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9l/nshq291949x2zhg9vq3gqqlh0000gn/T/ipykernel_78813/3222910497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from elementembeddings.core import Embedding\n",
    "from elementembeddings.plotter import heatmap_plotter, dimension_plotter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elemental representations\n",
    "\n",
    "A key problem in supervised machine learning problems is determining the featurisation/representation scheme for a material in order to pass it through a mathematical algorithm. For composition only machine learning, we want to be able create a numerical representation of a chemical formula A<sub>w</sub>B<sub>x</sub>C<sub>y</sub>D<sub>z</sub>. We can achieve this by creating a composition based feature vector derived from the elemental properties of the constituent atoms or a representation can be learned during the supervised training process.\n",
    "\n",
    "A few of these CBFV have been included in the package and we can load them using the `load_data` class method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the available CBFVs included in the package\n",
    "\n",
    "cbfvs = [\n",
    "    \"magpie\",\n",
    "    \"mat2vec\",\n",
    "    \"matscholar\",\n",
    "    \"megnet16\",\n",
    "    \"oliynyk\",\n",
    "    \"random_200\",\n",
    "    \"skipatom\",\n",
    "    \"mod_petti\",\n",
    "    \"magpie_sc\",\n",
    "    \"oliynyk_sc\",\n",
    "]\n",
    "\n",
    "# Create a dictionary of {cbfv name : Atomic_Embeddings objects} key, value pairs\n",
    "AtomEmbeds = {cbfv: Embedding.load_data(cbfv) for cbfv in cbfvs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the magpie representation as our example, we will demonstrate some features of the the `Embedding` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use magpie as our example\n",
    "\n",
    "# Let's look at the CBFV of hydrogen for the magpie representation\n",
    "print(\n",
    "    \"Below is the CBFV/representation of the hydrogen atom from the magpie data we have \\n\"\n",
    ")\n",
    "print(AtomEmbeds[\"magpie\"].embeddings[\"H\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the elements which have a feature vector for a particular embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also check to see what elements have a CBFV for our chosen representation\n",
    "print(\"Magpie has composition-based feature vectors for the following elements: \\n\")\n",
    "print(AtomEmbeds[\"magpie\"].element_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the elemental representations distributed with the package, we also included BibTex citations of the original papers were these representations are derived from. This is accessible through the `.citation()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the bibtex citation for the magpie embedding\n",
    "print(AtomEmbeds[\"magpie\"].citation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the dimensionality of the elemental representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can quickly check the dimensionality of this CBFV\n",
    "magpie_dim = AtomEmbeds[\"magpie\"].dim\n",
    "print(f\"The magpie CBFV has a dimensionality of {magpie_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the dimensionality of all of the CBFVs that we have loaded\n",
    "\n",
    "\n",
    "AtomEmbeds_dim = {\n",
    "    cbfv: {\"dim\": AtomEmbeds[cbfv].dim, \"type\": AtomEmbeds[cbfv].embedding_type}\n",
    "    for cbfv in cbfvs\n",
    "}\n",
    "\n",
    "dim_df = pd.DataFrame.from_dict(AtomEmbeds_dim)\n",
    "dim_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a wide range of dimensions of the composition-based feature vectors.\n",
    "\n",
    "Let's know explore more of the core features of the package.\n",
    "The numerical representation of the elements enables us to quantify the differences between atoms. With these embedding features, we can explore how similar to atoms are by using a 'distance' metric. Atoms with distances close to zero are 'similar', whereas elements which have a large distance between them should in theory be dissimilar. \n",
    "\n",
    "Using the class method `compute_distance_metric`, we can compute these distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue using our magpie cbfv\n",
    "# The package contains some default distance metrics: euclidean, manhattan, chebyshev\n",
    "\n",
    "metrics = [\"euclidean\", \"manhattan\", \"chebyshev\", \"wasserstein\", \"energy\"]\n",
    "\n",
    "distances = [\n",
    "    AtomEmbeds[\"magpie\"].compute_distance_metric(\"Li\", \"K\", metric=metric)\n",
    "    for metric in metrics\n",
    "]\n",
    "print(\"For the magpie representation:\")\n",
    "for i, distance in enumerate(distances):\n",
    "    print(\n",
    "        f\"Using the metric {metrics[i]}, the distance between Li and K is {distance:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue using our magpie cbfv\n",
    "# The package contains some default distance metrics: euclidean, manhattan, chebyshev\n",
    "\n",
    "metrics = [\"euclidean\", \"manhattan\", \"chebyshev\", \"wasserstein\", \"energy\"]\n",
    "\n",
    "distances = [\n",
    "    AtomEmbeds[\"magpie_sc\"].compute_distance_metric(\"Li\", \"K\", metric=metric)\n",
    "    for metric in metrics\n",
    "]\n",
    "print(\"For the scaled magpie representation:\")\n",
    "for i, distance in enumerate(distances):\n",
    "    print(\n",
    "        f\"Using the metric {metrics[i]}, the distance between Li and K is {distance:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "We can also explore the correlation between embedding vectors.\n",
    "In the example below, we will plot a heatmap of the pearson correlation of our magpie CBFV, a scaled magpie CBFV and the 16-dim megnet embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unscaled and scaled Magpie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 24))\n",
    "heatmap_plotter(\n",
    "    embedding=AtomEmbeds[\"magpie\"],\n",
    "    metric=\"pearson\",\n",
    "    sortaxisby=\"atomic_number\",\n",
    "    # show_axislabels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 24))\n",
    "heatmap_plotter(\n",
    "    embedding=AtomEmbeds[\"magpie_sc\"],\n",
    "    metric=\"pearson\",\n",
    "    sortaxisby=\"atomic_number\",\n",
    "    # show_axislabels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the above pearson correlation heatmaps, the visualisation of the correlations across the atomic embeddings is sensitive to the components of the embedding vectors. The unscaled magpie representation produces a plot which makes qualitative assessment of chemical trends difficult, whereas with the scaled representation it is possible to perform some qualitative analysis on the (dis)similarity of elements based on their feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 24))\n",
    "heatmap_plotter(\n",
    "    embedding=AtomEmbeds[\"megnet16\"],\n",
    "    metric=\"pearson\",\n",
    "    sortaxisby=\"atomic_number\",\n",
    "    # show_axislabels=False,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "dimension_plotter(\n",
    "    embedding=AtomEmbeds[\"magpie\"],\n",
    "    reducer=\"pca\",\n",
    "    n_components=2,\n",
    "    ax=ax,\n",
    "    adjusttext=True,\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "dimension_plotter(\n",
    "    embedding=AtomEmbeds[\"magpie_sc\"],\n",
    "    reducer=\"pca\",\n",
    "    n_components=2,\n",
    "    ax=ax,\n",
    "    adjusttext=True,\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "dimension_plotter(\n",
    "    embedding=AtomEmbeds[\"megnet16\"],\n",
    "    reducer=\"pca\",\n",
    "    n_components=2,\n",
    "    ax=ax,\n",
    "    adjusttext=True,\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "dimension_plotter(\n",
    "    embedding=AtomEmbeds[\"magpie\"],\n",
    "    reducer=\"tsne\",\n",
    "    n_components=2,\n",
    "    ax=ax,\n",
    "    adjusttext=True,\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "dimension_plotter(\n",
    "    embedding=AtomEmbeds[\"magpie_sc\"],\n",
    "    reducer=\"tsne\",\n",
    "    n_components=2,\n",
    "    ax=ax,\n",
    "    adjusttext=True,\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "dimension_plotter(\n",
    "    embedding=AtomEmbeds[\"megnet16\"],\n",
    "    reducer=\"tsne\",\n",
    "    n_components=2,\n",
    "    ax=ax,\n",
    "    adjusttext=True,\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "94b27d7815fced387b88df5b0ff93cedd6822b989d46e35c5073559e46421f5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
